{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2Pg-5wWTdH9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_absolute_error, confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from typing import List, Dict\n",
        "import random\n",
        "\n",
        "# job description\n",
        "JOB_DESCRIPTION = {\n",
        "    \"text\": \"We are looking for a Data Scientist with strong Python skills...\",\n",
        "    \"required_skills\": [\"Python\", \"Machine Learning\", \"Tableau\", \"SQL\", \"Pandas\", \"Scikit-learn\"],\n",
        "    \"education\": {\n",
        "        \"min_degree\": \"Master\",\n",
        "        \"fields\": [\"Computer Science\", \"Data Science\", \"Statistics\"]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Mock resume generator\n",
        "def generate_test_resumes(num_samples=100) -> List[Dict]:\n",
        "    \"\"\"Generate realistic test resumes with ground truth labels\"\"\"\n",
        "    test_resumes = []\n",
        "    degree_tiers = {\n",
        "        \"PhD\": 1.0,\n",
        "        \"Master\": 0.8,\n",
        "        \"Bachelor\": 0.6,\n",
        "        \"None\": 0.3\n",
        "    }\n",
        "\n",
        "    for i in range(num_samples):\n",
        "\n",
        "        skills = random.sample(JOB_DESCRIPTION[\"required_skills\"],\n",
        "                             k=random.randint(2, len(JOB_DESCRIPTION[\"required_skills\"])))\n",
        "\n",
        "\n",
        "        transferable_map = {\n",
        "            \"Tableau\": [\"PowerBI\", \"Looker\"],\n",
        "            \"Python\": [\"R\"],\n",
        "            \"Pandas\": [\"dplyr\"]\n",
        "        }\n",
        "        for skill, alts in transferable_map.items():\n",
        "            if skill in skills and random.random() > 0.7:\n",
        "                skills.append(random.choice(alts))\n",
        "\n",
        "\n",
        "        degree = random.choice(list(degree_tiers.keys()))\n",
        "        education_score = degree_tiers[degree]\n",
        "\n",
        "\n",
        "        experience = random.randint(0, 10)\n",
        "        experience_score = min(experience / 5, 1.0)\n",
        "\n",
        "\n",
        "        true_scores = {\n",
        "            \"skills\": len(skills) / len(JOB_DESCRIPTION[\"required_skills\"]),\n",
        "            \"education\": education_score,\n",
        "            \"experience\": experience_score,\n",
        "            \"total\": 0.5*(len(skills)/len(JOB_DESCRIPTION[\"required_skills\"])) +\n",
        "                    0.2*education_score +\n",
        "                    0.3*experience_score\n",
        "        }\n",
        "\n",
        "        should_accept = (\n",
        "            true_scores[\"skills\"] >= 0.6 and\n",
        "            degree in [\"Master\", \"PhD\"] and\n",
        "            experience >= 2\n",
        "        )\n",
        "\n",
        "        test_resumes.append({\n",
        "            \"text\": f\"\"\"\n",
        "                Name: Candidate_{i}\n",
        "                Education: {degree} in {random.choice(JOB_DESCRIPTION['education']['fields'])}\n",
        "                Experience: {experience} years\n",
        "                Skills: {', '.join(skills)}\n",
        "                Projects: Worked with {random.choice(skills)} on data analysis\n",
        "            \"\"\",\n",
        "            \"true_scores\": true_scores,\n",
        "            \"should_accept\": should_accept,\n",
        "            \"skills\": skills,\n",
        "            \"education\": degree,\n",
        "            \"experience\": experience\n",
        "        })\n",
        "\n",
        "    return test_resumes\n",
        "\n",
        "class ModelEvaluator:\n",
        "    def __init__(self, processor, scorer, job_desc, threshold=0.3):\n",
        "        self.processor = processor\n",
        "        self.scorer = scorer\n",
        "        self.job_desc = job_desc\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def evaluate(self, test_resumes: List[Dict]) -> Dict:\n",
        "        \"\"\"Full evaluation pipeline\"\"\"\n",
        "        results = {\"resumes\": [], \"metrics\": {}}\n",
        "\n",
        "        for resume in test_resumes:\n",
        "            try:\n",
        "                features = self.processor.extract_features(resume[\"text\"])\n",
        "                scores = self.scorer.calculate_scores(features, resume[\"text\"])\n",
        "\n",
        "                results[\"resumes\"].append({\n",
        "                    **resume,\n",
        "                    \"pred_scores\": scores,\n",
        "                    \"pred_accept\": scores[\"total_score\"] >= self.threshold,\n",
        "                    \"matched_skills\": list(set(features[\"skills\"]) &\n",
        "                                         set(self.job_desc[\"required_skills\"]))\n",
        "                })\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing resume: {str(e)}\")\n",
        "\n",
        "\n",
        "        self._compute_metrics(results)\n",
        "\n",
        "\n",
        "        self._generate_plots(results)\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _compute_metrics(self, results: Dict):\n",
        "        \"\"\"Calculate accuracy metrics\"\"\"\n",
        "        df = pd.DataFrame(results[\"resumes\"])\n",
        "\n",
        "\n",
        "        results[\"metrics\"] = {\n",
        "            \"skill_mae\": mean_absolute_error(\n",
        "                df[\"true_scores\"].apply(lambda x: x[\"skills\"]),\n",
        "                df[\"pred_scores\"].apply(lambda x: x[\"skill_score\"])\n",
        "            ),\n",
        "            \"education_mae\": mean_absolute_error(\n",
        "                df[\"true_scores\"].apply(lambda x: x[\"education\"]),\n",
        "                df[\"pred_scores\"].apply(lambda x: x[\"edu_score\"])\n",
        "            ),\n",
        "            \"experience_mae\": mean_absolute_error(\n",
        "                df[\"true_scores\"].apply(lambda x: x[\"experience\"]),\n",
        "                df[\"pred_scores\"].apply(lambda x: x[\"exp_score\"])\n",
        "            )\n",
        "        }\n",
        "\n",
        "        y_true = df[\"should_accept\"]\n",
        "        y_pred = df[\"pred_accept\"]\n",
        "\n",
        "        results[\"metrics\"].update({\n",
        "            \"accuracy\": np.mean(y_true == y_pred),\n",
        "            \"confusion_matrix\": confusion_matrix(y_true, y_pred),\n",
        "            \"classification_report\": classification_report(y_true, y_pred,\n",
        "                                                         target_names=[\"Rejected\", \"Accepted\"])\n",
        "        })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEhMiIDnWnfP",
        "outputId": "22103035-e18f-493e-84d0-6a63eb616cdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Evaluation Metrics ===\n",
            "Skill MAE: 0.172\n",
            "Education MAE: 0.118\n",
            "Experience MAE: 0.215\n",
            "\n",
            "Accuracy: 77.0%\n",
            "\n",
            "Confusion Matrix:\n",
            "[[44, 12], [11, 33]]\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Rejected       0.80      0.79      0.79        56\n",
            "    Accepted       0.73      0.75      0.74        44\n",
            "\n",
            "    accuracy                           0.77       100\n",
            "   macro avg       0.77      0.77      0.77       100\n",
            "            \n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    from HCAI_Project_latest import ResumeProcessor, ResumeScorer\n",
        "    processor = ResumeProcessor()\n",
        "    scorer = ResumeScorer(JOB_DESCRIPTION)\n",
        "\n",
        "\n",
        "    test_resumes = generate_test_resumes(100)\n",
        "\n",
        "\n",
        "    evaluator = ModelEvaluator(processor, scorer, JOB_DESCRIPTION)\n",
        "    results = evaluator.evaluate(test_resumes)\n",
        "\n",
        "\n",
        "    print(\"=== Evaluation Metrics ===\")\n",
        "    print(f\"Skill MAE: {results['metrics']['skill_mae']:.3f}\")\n",
        "    print(f\"Education MAE: {results['metrics']['education_mae']:.3f}\")\n",
        "    print(f\"Experience MAE: {results['metrics']['experience_mae']:.3f}\")\n",
        "    print(f\"\\nAccuracy: {results['metrics']['accuracy']:.1%}\")\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(results[\"metrics\"][\"confusion_matrix\"])\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(results[\"metrics\"][\"classification_report\"])\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
