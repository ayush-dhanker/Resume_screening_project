# Evaluating Transparency in User Profiling to improve clarity for Resume Screening Systems

## Abstract 
Adoption of AI-based resume screening systems gained momen-
tum across the recruitment industry, but continuance of black-box
algorithmic decision-making undermined user trust and justice
perception. In the present study, we design and test, to an extent, a
human-centered transparent resume screening model to critique
where candidates may permeate clear and actionable feedback about
the fate of their applications. Using a prototype web platform built
around advanced natural language processing and explainable AI
techniques, our system produces individual rejection explanations
to enhance user understanding and agency. We perform a structured
user study to assess transparent explanation impacts on applicant
trust, perceived fairness, and overall experience. Our findings shall
show that transparent AI-based explanation benefits user satisfac-
tion and remedies unethical cases against human-centered design
where automation of hiring occurs.

## Summary
This paper discusses the construction of a transparent Artificial
Intelligence-based resume screening system developed from Human-
Centered AI, or HCAI, with elements of fairness, explainability,
and user empowerment. Unlike most existing automated screening
tools, our system attempts to generate useful feedback information
for the applicant: regarding why his application was not accepted
or rather rejected. Using natural language processing and seman-
tic analysis, the system will appraise resumes in several dimen-
sions—skills, education, and experience—and deliver more than
an actual human-readable explanation. Thus, the feedback system
purposefully turns rejection from some ill-defined fraught end into
explicit opportunity for betterment.To judge the efficiency and hu-
man effect of the system, a real-user study was carried out in which
participants interacted with the prototype and later responded to a
structured survey questionnaire. Results indicated an overwhelm-
ingly strong preference for transparent feedback, that is, users trust
more and perceive fairness when they clearly understand the out-
come of their applications. This insight sits well with other findings
that control and explanation are what applicants desire most when
interacting with AI in such high-stake contexts as hiring
